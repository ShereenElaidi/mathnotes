\documentclass[11pt]{scrartcl}
\usepackage[margin=2cm]{geometry}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb,amsmath,amsthm}
\usepackage{xcolor} 
\usepackage{enumitem}
\newcommand{\R}[0]{\mathbb{R}}
\addtokomafont{section}{\rmfamily\centering\scshape}
% math environments 
\usepackage[utf8]{inputenc}
\theoremstyle{definition}
\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{definition}{Definition}
\newtheorem{prop}{Proposition}
\newtheorem{ex}{Example}
\theoremstyle{remark}
\newtheorem*{remark}{Remark}
\usepackage[ruled,vlined]{algorithm2e}
% definition
\newcommand{\dfn}[1]{\textbf{\underline{#1}}}
\newcommand{\dist}[0]{\mathcal{F}}
\newcommand{\pr}[1]{\mathbb{P}[#1]} 
\newcommand{\stat}[0]{T(X_1, ..., X_n )} 

% converge in probability 
\newcommand{\cvp}[0]{\overset{p}{\to}}

% sample mean
\newcommand{\smean}[0]{\frac{1}{n} \sum_{i=1}^n x_i} 

% sample variance
\newcommand{\svar}[0]{\frac{1}{(n-1)} \sum_{i=1}^n (x_i - \overline{x})^2}

% expected value 
\newcommand{\EX}[1]{\mathbb{E}\left[#1 \right]}  
\newcommand{\EXth}[1]{\mathbb{E}_\theta \left[ #1 \right]}

% integral
\newcommand{\idx}[2]{\int_{#1}^{#2}}

% vector
\newcommand{\vect}[1]{\mathbf{#1}}


\title{\textbf{Comp 551: Applied Machine Learning}}
\author{Shereen Elaidi}
\date{Winter 2020 Term}

\begin{document}

\maketitle
\tableofcontents

\section{Week 1}
\subsection{Learning Objectives}
\section{Week 2}
\subsection{Learning Objectives}
\begin{enumerate}[noitemsep]
	\item Linear Regression
	\begin{enumerate}[noitemsep]
		\item Linear model 
		\item Evaluation Criteria 
		\item How to find the best fit 
		\item Geometric interpretation 
	\end{enumerate}
	\item Logistic Regression
	\begin{enumerate}[noitemsep]
		\item Linear Classifier 
		\item Logistic regression -- model 
		\item Logistic regression -- loss function
		\item Maximum likelihood view 
		\item Multi-class classification
	\end{enumerate}
\end{enumerate}

\subsection{Linear Regression}
The whole idea behind linear regression is that we want our output to be an \emph{linear} combination of the features. We don't care about the linearity of the features themselves; for all we care the features themselves can encode non-linear relations. The objective of \dfn{linear regression} is to learn a function of the form: 
\begin{align}
	f_W(X) = w_0  + \sum_{j=1}^m w_j x_j
\end{align}
Where $X$ is a matrix encodes our features (each row represents one feature) and $W$ encodes the weights that we are supposed to learn. $w_0$ is the bias/offset term. In linear regression, the most common choice of error function is the \dfn{squared error}: 
\begin{align*}
	\text{Err}(W) := \sum_{i=1}^n (y_i - w^t x_i)^2
\end{align*}
Some remarks on the squared error: 
\begin{itemize}[noitemsep]
	\item We take the \emph{squared} error since we want to take gradients. There are also other more statistical reasons behind why this is the most common choice of error function in regression. 
	\item The other most common error is something called the \dfn{cross-entropy} error. A situation where we would want to use cross-entropy error over squared error is if the output is bounded; in this case, this is not the right thing to do. Why? 
	\begin{itemize}[noitemsep]
		\item Least squared error assumes that the noise is Gaussian distributed. Gaussian distributions are NOT bounded. So, if we were trying to learn a Bernoulli model, in which the output is bounded, this would not be correct. 
	\end{itemize}
\end{itemize}

The \dfn{least-squared closed form solution} is what we obtain when we take the derivative of the error and set it equal to zero. The closed form solution is: 
\begin{align}\label{reg:closed} 
	\hat{W} = (X^t X)^{-1} X^t Y 	
\end{align}
\begin{itemize}[noitemsep]
	\item The run time to compute $\hat{W}$ using the closed-form solution (\ref{reg:closed}) is polynomial, which is quite reasonable.  
	\item There are two primary failure modes of this way: 
	\begin{enumerate}[noitemsep]
		\item $(X^tx)$ is a singular matrix (i.e., not invertible). 
		\item A linear function is not the right fit. 
	\end{enumerate}
\end{itemize}

We will now address these failure modes in more detail. 

\subsubsection{Failure Mode \# 1: Avoiding Singularities}
We require that $X$ has full column-rank, since we are inverting matrices here. This means that \emph{features cannot be linearly correlated with each other}. This would happen if our features are redundant; this redundancy would break the model. There are two cases in which this can occur: 
\begin{enumerate}[noitemsep]
	\item The Weights are Not Uniquely defined: 
	\begin{enumerate}[noitemsep]
		\item This can occur when \emph{one feature is a linear function of the other}. The way you deal with this is by scrapping out redundant features. 
		\item A concrete example of this is if you had a model that included the number of clicks per day and the rate of clicks per hour in $X$. 
	\end{enumerate}
	\item The number of features ($m$) exceeds the number of training examples. 
	\begin{enumerate}[noitemsep]
		\item In this case, you must either drop features or use \emph{regularisation} (will discuss this later). 
		\item Interesting from a ML perspective. 
	\end{enumerate}
\end{enumerate}

\subsubsection{Failure Mode \# 2: Linear Function is a Bad Fit}
In this case, we would need to either: 
\begin{enumerate}[noitemsep]
	\item Pick a better function. 
	\item Use more features. 
	\item Get more data
\end{enumerate}
This failure mode leads into the idea of transforming features. Maybe we can preserve a linear model, but perhaps use non-linear bases? 

\subsection{Input Features for Linear Regression -- Feature Engineering}
Suppose that our original quantitative variables are $X_1, ..., X_n$. For various reasons, we may wish to take a transformation of variables. 
\begin{enumerate}[noitemsep]
	\item We may want to take the logarithm $\log(X_i)$. This is useful when we are dealing with count data. These data points tend to come from what are called \dfn{heavy-tailed} distributions. If we do not transform these data points, the model may become confused. 
	\item We can also do \dfn{basis expansions}: suppose that instead of having $X_m$, we can set $X_{m+} = X_m^2$. 
	\item We can create \dfn{interaction terms}: this is useful when both terms are important. For example, we can set $X_{m+1} = X_i X_j$, which means we only care when both $X_i$ and $X_j$ are happening at the same time. Since this is a non-linear relation between $X_i$ and $X_j$, this is okay since it will not create linear dependencies amongst our features. 
	\item Numeric coding of qualitative features or one-hot encoding. 
\end{enumerate}
Variable coding is not always straightforward. Suppose we have $X_{\text{cat}} = \{$ green, blue, yellow, red $\}$. A first naive way to one-hot encode this is to make four separate binary variables. However, this could lead to singularities; we actually only need three binary variables. What we need to do is arbitrarily choose one of the categories to be the ``basis'' category. 

If our input is raw text, then we need to get creative:
\begin{enumerate}[noitemsep]
	\item Word counts? 
	\item Average word length?
	\item Number of words per sentence? 
\end{enumerate}
All of the above are examples of \dfn{feature design}; which will be a recurrent theme throughout the course. In general, we should avoid categorical encoding such as $\{ 1, 2, 3, 4, ... \}$, as these can create artificial closeness between categorical features in feature space, which may mislead the model. 


\subsection{Overfitting \& Generalisation}

If we find a model that is able to perfectly fit the training data but does not generalise to new data, we are observing \dfn{overfitting}. 
\begin{enumerate}[noitemsep]
	\item Very important problem in ML. 
	\item We want to minimise the \dfn{true} error. The only way we can do this is if we use the training set as a proxy for data that we don't have. 
	\item We can \emph{formally express overfitting} as: suppose we compare hypotheses $f_1$ and $f_1$ and suppose that $f_1$ has a lower error on the training set. Then, if $f_2$ has a lower true error, then our model is overfitting. 
\end{enumerate}
With that in mind, the goal in ML is to develop models that \dfn{generalise} previously unseen data. \emph{How do we evaluate this}? 
\begin{enumerate}[noitemsep]
	\item We need to evaluate on held-out data. This introduces the concept of a \dfn{train/test/validate-split}: 
	\begin{enumerate}[noitemsep]
		\item \dfn{Training set} $\rightarrow$ use this to fit the model (i.e., choose the best hypothesis in the class). 
		\begin{enumerate}[noitemsep]
			\item Most of the data will be used for this. 
		\end{enumerate}
		\item \dfn{Validation set} $\rightarrow$ compare different choices of feature selection. This also gives us a rough idea of how well our model is \emph{actually} doing. 
		\begin{enumerate}[noitemsep]
			\item This is like our ``sandbox''
			\item Use to compare different models during development, e.g.: should.I use a first- or second- order polynomial fit? 
			\item Also can be used to compare \dfn{hyper-parameters} (i.e., a parameter that is NOT learned but can impact the performance, such as the learning rate). 
		\end{enumerate}
		\item \dfn{Test set} $\rightarrow$ we should only use this dataset to report our final accuracy. Do not use this dataset to train!
	\end{enumerate}
\end{enumerate}


\subsubsection{K-Fold Cross Validation}
This is a very effective approach to see how the model is generalising. It is also a good technique when you have a small dataset, and so don't want to throw out a lot of data. 

The way \dfn{k-fold cross validation} is as follows: consider $k$ partitions of the training or non-test data. For each partition, train with $k -1$ subsets, and then validate on the $k$th. Repeat this $k$ times. You then average the prediction error over the $k$ rounds or folds. \textbf{Run-time remark}: this increases the computation by a factor of $k$. 

A more extreme version of $k$-fold cross validation is \dfn{leave} \dfn{one} \dfn{out} \dfn{cross-validation}. Let $k=n$, the size of the training set. For each model or hyper-parameter setting: for $n$ times, set aside one instance from the training set. Use all the other data points to find $w$ (this is the optimisation step), and measure the prediction error on the held out datapoint. Then, average the prediction over all $n$ subsets. \textbf{Run-time remark}: this gets pretty computationally expensive. 


\section{Week 3}

\subsection{Learning Objectives}
\begin{enumerate}
	\item Naive Bayes Classifier 
	\begin{enumerate}[noitemsep]
		\item Generative vs. discriminative classifier 
		\item Naive Bayes classifier -- assumption 
		\item Naive Bayes classifier -- different design choices
	\end{enumerate}
\end{enumerate}

\section{Week 4}

\subsection{Learning Objects}
\begin{enumerate}
	\item Regularisation 
	\begin{enumerate}[noitemsep]
		\item Overfitting and underfitting
		\item Regularisation (L1 and L2) 
		\item MLE vs MAP estimator 
		\item Bias and variance tradeoff 
		\item Evaluation metrics and cross-validation
	\end{enumerate}
\end{enumerate}

\section{Week 5}
\subsection{Learning Objectives}
\begin{enumerate}[noitemsep]
	\item Gradient Descent Methods 
	\begin{enumerate}[noitemsep]
		\item Gradient Descent 
		\item Stochastic Gradient Descent 
		\item Method of momentum 
		\item Sub-gradient 
		\item Application to linear regression and classification 
	\end{enumerate}
	\item Evaluation
	\begin{enumerate}[noitemsep]
		\item Different types of error 
		\item Common evaluation metrics
		\item Cross validation
	\end{enumerate}
\end{enumerate}
\section{Week 6}
\dfn{Topics covered}: perceptron, max margin classifier, support vector machines, soft margin constraints, hinge loss, decision trees, greedy heuristic, entropy, mutual information, gini index, and overfitting. 

\subsection{Learning Objectives}
\begin{enumerate}[noitemsep]
	\item Perceptron and Support Vector Machines 
	\begin{enumerate}[noitemsep]
		\item The geometry of linear classification
		\item Perceptron learning algorithm
		\item Margin maximisation and support vectors 
		\item Hinge loss and relation to logistic regression 
	\end{enumerate}
	\item Decision Trees
	\begin{enumerate}[noitemsep]
		\item Decision Trees: model, cost function, and how it is optimised. 
		\item How to grow a tree and why you should prune. 
	\end{enumerate}
\end{enumerate}

\subsection{Perceptron}
The \dfn{perceptron} is the first machine learning algorithm. The assumption made by the perceptron is that given the data, there must be a hyperplane that separates one class from another. It additionally assumes that the data is binary, however we can later extend this to multi-class predictions. That is, for a binary classifier, all the points of one class lie on one side of a hyperplane, and the other points lie on the other side of a hyperplane. In high dimensional spaces, this almost always holds. This doesn't really happen often in lower-dimensional spaces. You can actually prove that this always holds in \emph{infinite-dimensional} spaces. 

In some sense, the perceptron is the opposite of the KNN. The KNN is very nice in low-dimensional spaces, because you don't need to deal with the ``curse of dimensionality'' and it's also much faster in lower-dimensional spaces. The perceptron is optimal for high-dimensional spaces. Moreover, KNN is not a linear classifier. For KNN, the decision boundaries are not necessarily linear (as we saw on the quiz); however, for the perceptron method it \emph{must} be linear. 

Assuming that such a hyperplane exists, the perceptron tries to find it. To mathematically define a hyperplane, you need a normal vector $w$ and a bias term $b$: 
\begin{align}
	\mathcal{H}:= \{ x \in \R^n\ |\ w^t x + b = 0 \} 	
\end{align}
it has one less dimension than the ambient space. During test time, if you get an unknown point $x$, you classify it based on which side of the hyperplane it lies on. This is nice since  computing which side of the hyperplane that the point lies on is always the same; all you need to do is compute sgn($w^t x + b$). 

\subsubsection{How can we find the hyperplane?}

The way that we formalise that our label set is binary is by writing: 
\begin{align*}
	\mathcal{Y} = \{ -1, +1 \} 	
\end{align*}
We have to learn two things: $w$ and $b$. We want to learn only one thing, so assume that there is no offset. So, compute the following maps: 
\begin{align*}
	& x_i \mapsto \begin{bmatrix}
		x_i \\
		1 
	\end{bmatrix}	\\
	& w \mapsto \begin{bmatrix}
		w \\
		b
	\end{bmatrix} 
\end{align*}
This is valid since 
\begin{align*}
 	\left\langle 	\begin{bmatrix}
		x_i \\
		1 
	\end{bmatrix} , \begin{bmatrix}
		w \\
		b
	\end{bmatrix} \right\rangle = w^tx + b 
\end{align*}
This transformation just absorbs $b$ into the data. This is reflected in the new hyperplane: 
\begin{align*}
	\mathcal{H} := \{ x \in \R^{n+1}\ |\ w^tx = 0 \}
\end{align*}
Geometrically, what we are doing is insisting that our hyperplane now goes through the origin. It will still be the same solution, just in a higher dimension. 

\subsubsection{The Algorithm}
\dfn{High-level intuition}: Every time you get a point wrong, you adjust your hyperplane. Loop over the dataset. Once you make no more mistakes, you know you've found a hyperplane that separates the data, and then you stop. 

\begin{algorithm}[H]
\SetAlgoLined
\KwResult{Perceptron Algorithm}
 $w=0$ (set weights to zero, this will get everything wrong)\;
 \While{true}{
  $m=0$ (the counter of how many pts mis-classified)\;
 \For{$\forall$ $(x, y) \in \mathcal{D} $}{ 
 	(checks which side of the hyperplane you are on:)\; 
 	\If{$yw^tx \leq 0$} {
 		(this is the case if and only if the point is wrong, since you want the signs to align.)\; 
 		$w \leftarrow w^tyx$ \; 
 		(the above piece of code tries to reinforce the points if positive to make positive larger inner products, negative points have small inner products)\; 
 		$m \leftarrow m+1$ \; 
 	} 
 	\If{$m=0$}{
 		(do this until you make a full pass over the dataset without getting anything wrong)\; 
 		break\; 
 	} 
 	} 
 }
 \caption{Perceptron Algorithm}
\end{algorithm}

Some observations: the algorithm will take a long time if there is a lot of ``wiggle room'' between the data points (this is encoded by what is called the  \dfn{margin size}, which will be discussed later), since it's easy to continue to offshoot the ideal hyperplane. 

The \dfn{Perceptron Convergence Theorem} asserts that the algorithm is guaranteed to converge in a finite number of steps if our data is linearly separable. For a given $x$, the amount of times at which we get $x$ incorrectly, encoded by $k$, is at most: 
\begin{align}
	k \leq \frac{w^tx}{x^t x}
\end{align}

\end{document}