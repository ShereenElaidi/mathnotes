\documentclass[11pt]{scrartcl}
\usepackage[margin=2cm]{geometry}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb,amsmath,amsthm}
\usepackage{xcolor} 
\usepackage{enumitem}
\usepackage{tikz} 
\usepackage{float}
\usepackage{color}
\definecolor{myblue}{rgb}{.8, .8, 1}
\usetikzlibrary{shapes.geometric,calc}
\addtokomafont{section}{\rmfamily\centering\scshape}
% math environments 
\usepackage[utf8]{inputenc}
\theoremstyle{definition}
\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{definition}{Definition}
\newtheorem{prop}{Proposition}
\newtheorem{ex}{Example}
\newtheorem{claim}{Claim}
\theoremstyle{remark}
\newtheorem{remark}{Remark}
% boxes
\usepackage{empheq}
\usepackage{hyperref}
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=black,
    urlcolor=black
}

\newlength\mytemplen
\newsavebox\mytempbox

\makeatletter
\newcommand\mybluebox{%
    \@ifnextchar[%]
       {\@mybluebox}%
       {\@mybluebox[0pt]}}

\def\@mybluebox[#1]{%
    \@ifnextchar[%]
       {\@@mybluebox[#1]}%
       {\@@mybluebox[#1][0pt]}}

\def\@@mybluebox[#1][#2]#3{
    \sbox\mytempbox{#3}%
    \mytemplen\ht\mytempbox
    \advance\mytemplen #1\relax
    \ht\mytempbox\mytemplen
    \mytemplen\dp\mytempbox
    \advance\mytemplen #2\relax
    \dp\mytempbox\mytemplen
    \colorbox{myblue}{\hspace{1em}\usebox{\mytempbox}\hspace{1em}}}

\makeatother


% definition
\newcommand{\dfn}[1]{\textbf{\underline{#1}}}
\newcommand{\dist}[0]{\mathcal{F}}
\newcommand{\pr}[1]{\mathbb{P}[#1]} 
\newcommand{\stat}[0]{T(X_1, ..., X_n )} 

% converge in probability 
\newcommand{\cvp}[0]{\overset{p}{\to}}

% sample mean
\newcommand{\smean}[0]{\frac{1}{n} \sum_{i=1}^n x_i} 

% sample variance
\newcommand{\svar}[0]{\frac{1}{(n-1)} \sum_{i=1}^n (x_i - \overline{x})^2}

% expected value 
\newcommand{\EX}[1]{\mathbb{E}\left[#1 \right]}  
\newcommand{\EXth}[1]{\mathbb{E}_\theta \left[ #1 \right]}

% integral
\newcommand{\idx}[2]{\int_{#1}^{#2}}

% vector
\newcommand{\vect}[1]{\mathbf{#1}}

% symbols
\newcommand{\R}[0]{\mathbb{R}}

% inner product
\newcommand{\ip}[2]{\left\langle #1, #2 \right\rangle}


\title{\textbf{Math 475: Partial Differential Equations}}
\author{Shereen Elaidi}
\date{Fall 2019 Term}

\begin{document}

\maketitle
\tableofcontents

\section{Introduction}

\textbf{Q:} Where do PDE's come from? PDEs are used in all types of math modelling; they translate phenomena coming from physics, biology, chemistry, etc. into mathematical terms. 
\newline 
\newline 
\textbf{Q:} What goes into a PDE model? 
\begin{center}
	Math model = General Physical Laws (balancing forces and conservation of quantities) + Constitutive Relations (Laws specific to the environment, e.g. Fick's Law of Diffusion) 
\end{center}
A PDE $\leftrightarrow$ a physical description of a system. 

\begin{definition}[PDE]
	A \dfn{PDE} is a mathematical relation involving partial derivatives, i.e., if $\vect{u}: \R^n \rightarrow \R$, $\vect{x} = (x_1, ..., x_n)$ a real-valued function of several variables, then any kth order PDE can be expressed as: 
	\begin{align}
		F(D^k \vect{u}, D^{k-1} \vect{u}, ..., D \vect{u}, \vect{u}, \vect{x} ) = 0 \text{ in } \Omega 	
	\end{align}
	where $\Omega \subseteq \R^n$ is the domain or region where the PDE holds, and $F$ is a function of the placeholders. 
\end{definition}

\begin{definition}[$C^k$ and $C^k(\Omega)$] A function $\vect{u}: \R^n \rightarrow \R$ is $C^k$ at a point $\vect{x} \in \R^n$ if every kth-order partial derivative is continuous as a function of $\R^n$ at $x$. If $u \in C^2(\R^n)$, then in advanced calculus it was proven that $D^2u$ is a symmetric matrix. 
\end{definition}

\begin{ex}[Examples of PDEs] 
	\begin{enumerate}[noitemsep]
		\item \dfn{Heat Equation}: 
		\begin{align}
				u_t - k \Delta u = u_t - k \sum_{i=1}^n u_{x_i x_i} = 0 
		\end{align}
		where $k > 0$ is a constant. Then the solution has a space- and time- component: 
		\begin{align}
			u(\vect{x}, t) = u: \R^{n+1} \rightarrow \R 
		\end{align}
	\item \dfn{Laplace's Equation}: 
	\begin{align}
			- \Delta u = 0 
	\end{align}
	$u(x)$ is the steady state of a solution to the heat equation, since $u_t = 0 \Rightarrow$ ``constant in time.'' The solution $u$ is a function $u: \R^n \rightarrow \R$. 
	\item \dfn{Wave Equation}: 
	\begin{align*}
		& u_{tt} - \Delta u = 0 \\
		& u: \R^{n+1} \rightarrow \R 
	\end{align*}
	$u(x,t)$ is the displacement of an object with wave-like behaviour at location $\vect{x}$ and time $t$. Ex: position of a guitar string. 
	\item \dfn{Transport Equation}: 
	\begin{align*} 
		u_t + cu_x = 0,\ c \in \R, u: \R^2 \rightarrow \R \text{ (space, time) } 
	\end{align*} 
	$u(x,t)$ can be the density of a pollutant at location $\vect{x}$ and time $t$. 
	\item  \dfn{Reaction-Diffusion}: 
	\begin{align*}
		& u_t - k \Delta u = f(u) \\
		& u: \R^{n+1} \rightarrow \R \\
		& f: \R \rightarrow \R 	
	\end{align*}
	$u( \vect{x},t)$ can be the temperature at location $(\vect{x}, t)$ subject to enhancement by $f(u)$ (for example, fire spreading). 
	\item \dfn{Burger's Equation}: 
	\begin{align}
		u_t - u u_x = vu_{xx} 
	\end{align}
	$v > 0$ represents the viscosity. $u: \R^2 \rightarrow \R$, $u(x,t)$ is the concentration of a material in a fluid flow with convection. 
	\end{enumerate}	
\end{ex}

\subsection{Domains and Boundary Conditions}

\begin{definition}[$C^1$ domain] 
	$\Omega \subseteq \R^n$ is a \dfn{$C^1$ domain} if $\partial \Omega$ can locally be expressed as a graph of a $C^1$ function. This means...
	\begin{enumerate}[noitemsep]
		\item $\partial \Omega$ has no corners $\Rightarrow$ smooth. 
		\item $\forall p \in \partial \Omega$, there exists a well-defined and unique tangent plane (whose slope is given by the derivative), which implies that there exists a well-defined inward and outward normal vector. 
		\item Inward and outward normal vectors move continuously along $\partial \Omega$. 
	\end{enumerate}
\end{definition}

\subsubsection{What are the main boundary conditions?}
\begin{enumerate}[noitemsep]
	\item \dfn{Dirichlet Boundary Conditions}: these prescribe what $u$ is on $\partial \Omega$. We assume that $u \in C^k(\Omega) \cap C(\partial \Omega)$. 
	\item \dfn{Neumann Boundary Conditions}: these prescribe what the normal derivative of $u$ on $\partial \Omega$ is. The meaning behind this is: \emph{how does $u$ change along the boundary}? It is specifying:
	\begin{align}
		\frac{\partial u}{\partial n} = \nabla u \cdot n(x) = X \text{ on } \partial \Omega 	
	\end{align}
	\item \dfn{Robin boundary conditions}: a combination of the above: 
	\begin{align}
		\frac{\partial u}{\partial n} + \alpha u = X \text{ on } \partial \Omega 
	\end{align}
\end{enumerate}
In general, in PDEs, we will not be able to identify an explicit solution. Thus, we care about the following four fundamental issues. The first three ensure that we have a \emph{well-posed problem}, and the final one is important when we cannot obtain an explicit solution. 
\begin{enumerate}[noitemsep]
	\item \emph{Existence}: is there a solution? 
	\item \emph{Uniqueness}: is there exactly one solution to the PDE?
	\item \emph{Stability}: does the solution depend continuously on the data? 
	\item \emph{Qualitative Properties}: If I cannot find an explicit solution, but I know that it exists, what else can I tell you about the solution? Some questions we are interested in studying are: 
	\begin{enumerate}[noitemsep]
		\item Does $u(\vect{x}, t) \rightarrow 0$ as $t \rightarrow \infty$? 
		\item What is $\max_\Omega |u(\vect{x})|$? 
	\end{enumerate}
\end{enumerate}

\subsection{Classification of PDEs} 
To do: draw out the chart 

When we have a PDE that's linear in $D^2u$, we can always express our PDE in the form of a matrix: 
\begin{align}
	F(D^2u, Du, u, x) = \underbrace{- \sum_{i=1}^n \sum_{j=1}^n A_{ij}(x) u_{x_ix_j}}_{:=L[u]}  + G(Du, u, x) 
\end{align}
where $A \in $ MAT$(n \times n, \R)$ is symmetric, since $u \in C^2$. $L[u]$ is a linear operator that maps functions to functions and is of the form
\begin{align}
	L[u] = -\text{tr}( A(x) D^2(u)) 	
\end{align}
Therefore, we can write linear, second-order PDEs in the following form: 
\begin{align}
	-\text{tr}(A(x) D^2 u) = G(Du, u,x) 	
\end{align}
This is useful since we can classify second-order PDEs in terms of the eigenvalues of $A$. We will now give definitions for the three main types of PDEs: 

\begin{definition}[Elliptic PDE]
	A PDE is \dfn{elliptic} if $\forall x$, $A(x)$ has non-zero eigenvalues, all of which have the same sign. 
\end{definition}

The model equation for an elliptic PDEs is: 
\begin{align}
	- \Delta u = -\sum_{i=1}^n u_{x_i x_i} = - \sum_{i,j =1}^n A_{ij}(x) i_{x_i x_j} 	
\end{align}
where 
\begin{align}
	A(x) = \begin{bmatrix}
		1 &  &  & \\
		  & 1 & & \\
		  &  &  \ddots & \\
		  & & & 1 
	\end{bmatrix}	
\end{align}

\begin{definition}[Hyperbolic PDE]
	A PDE is \dfn{hyperbolic} if $\forall x$, $A_{ij}(x)$ has non-zero eigenvalues, all of the same sign except for one. 
\end{definition}

The model equation for a hyperbolic PDE is: 
\begin{align}
	\text{ wave equation: } u_{tt} - \Delta u = - \text{tr} (A(x,t) D_{x,t}^2 u ) 	
\end{align}
where 
\begin{align}
	A(x,t) = 	\begin{bmatrix}
		1 &  &  & \\
		  & \ddots & & \\
		  &  &  1 & \\
		  & & & -1
	\end{bmatrix}	
\end{align}

\begin{definition}[Parabolic PDE]
	A PDE is \dfn{parabolic} if $\forall x$, $A(x)$ has at least one zero eigenvalue. 
\end{definition}

The model equation for a parabolic PDE is: 
\begin{align}
	\text{ Heat Equation: } u_t - \Delta u = - \text{tr}(A_{ij}(x) D_{x,t}^2 u) + u_t 	
\end{align}
where 
\begin{align}
	A(x,t) = 	\begin{bmatrix}
		1 &  &  & \\
		  & \ddots & & \\
		  &  &  1 & \\
		  & & & 0
	\end{bmatrix}_{(n+1, n+1)}	
\end{align}

\begin{remark}
	Typically, a parabolic PDE can be written down as $u_t + $ elliptic PDE. Thus, we would expect them to have similar properties (which they do, as we will see later). 
\end{remark}
In this course, we'll focus on heat, wave, and Laplace's equations as models of parabolic, hyperbolic, and elliptic PDEs. 

\section{Diffusion}
\textbf{Physical Phenomena:} heat flow, diffusion of ink, and transport of a substance due to the molecular motion of the surrounding medium. 

\subsection{Derivation and Setting Up $(n=1)$}
Let $u(x,t)$ be the temperature at location $x \in \R$, and let $t$ be the time, $t > 0$. We're going to consider a rod of length $L$, going from $x=0$ to $x=L$. We will assume perfect insulation of the tube as well as constant mass density. This gives us a one-dimensional model, since heat is flowing in only one direction. In the rod, consider an cross section $S$.   


Define the following quantities: 
\begin{align*}
	& e(x,t) := \text{ thermal energy / unit mass } \\
	& q(x,t) := \text{ heat flux (rate of flow per unit area) } \\
	& \rho := \text{ mass density per unit volume} \\
	& r(x,t) := \text{ rate / unit mass of the external heat source} 	\\
	& \rho(1/A) := A 
\end{align*} 
The general physical law that we will use is: 
\begin{align*}
	\text{ Rate of thermal energy change in } S =  \text{ heat in } - \text{ heat out (via the ends) }
\end{align*} 
\begin{enumerate}[noitemsep]
	\item For the rate of thermal energy change in $S$, we have that this equals the derivative with respect to dime of the thermal energy in $S$. If we let $x_0$ be the left end point of $S$ and $x_0 + \Delta x$ be the right end point of $S$, then the total thermal energy in $S$ equals
	\begin{align}
		\text{ thermal energy in } S = \int_{x_0}^{x_0 + \Delta x} e(x,t) \rho A dx := E(t) 
	\end{align}
	where $e(x,t)$ is the thermal energy per unit area, $\rho$ is the density, and $A$ is the area. Assuming that we can interchange the derivative with the limit, we obtain: 
	\begin{align}
		\frac{dE}{dt} = \idx{x_0}{x_0 + \Delta x} \frac{\partial e}{\partial t} e(x,t) \rho A dx 	
	\end{align}
	\item Now for the heat in $-$ heat out via the ends term, we need to account for both the external heat source and the heat flow through the ends. Contribution from an external heat source could be from an electric current or a chemical reaction. We will use the \dfn{law of conservation of energy}, which can be formulated as: \emph{the time rate of change of thermal energy in $S$ = the net flux through $\partial S$ due to conduction $+$ time rate at which heat is supplied by the external sources }. Therefore, the contribution from the heat source is given by: 
	\begin{align*}
		\idx{x_0}{x_0 + \Delta x} r(x,t) \rho A dx 	
	\end{align*}
	and the flux through the ends is divergence, meaning that
	\begin{align*}
		\text{flux} = -q(x,t) \cdot n
	\end{align*}
	where $n$ is the outward unit normal. Therefore, the energy flow rate through $[x, x+ \Delta x]$ is $-(q(x_0+ \Delta x, t) - q(x_0, t)) \cdot A$. If $q$ is differentiable in $x$ then by the fundamental theorem of calculus, we obtain: 
	\begin{align}
		\text{flux} = - \idx{x_0}{x_0 + \Delta x} A \frac{\partial q}{\partial x} q(x,t) dx 	
	\end{align}
	So, putting all the previous equations together, by the general physical laws we obtain: 
	\begin{align}\label{generalphyslaws}
		\idx{x_0}{x_0 + \Delta x} \frac{\partial e}{\partial t} [ e(x,t)] \rho A dx = \idx{x_0}{x_0 + \Delta x} r(x,t) \rho A dx - \idx{x_0}{x_0 + \Delta x} A \frac{\partial q}{\partial x} q(x,t) dx
	\end{align}

\end{enumerate}
The constitutive relations that we will use are the \dfn{Fourier Law of Heat Conduction} and a relationship between thermal energy and temperature. 
\begin{enumerate}[noitemsep]
	\item \dfn{Fourier Law of Heat Conduction}: Heat flux is a linear combination of the temperature gradient heat flows from hot to cold. For $\kappa >0$ a constant, this is expressed as: 
	\begin{align}
		q(x,t) = - \kappa u_x	
	\end{align}
	(If the temperature is decreasing with respect to space, then heat is flowing out and the flow is positive). 
	\item For thermal energy, we have that it is a linear function of the absolute temperature. Let $c > 0$ be the specific heat. Then: 
	\begin{align}
		e(x,t) = cu(x,t) 
	\end{align}
	Which implies that
	\begin{align*}
		\frac{\partial e}{\partial t} = cu_t \text{ and } \frac{\partial q}{\partial x} = - \kappa u_{xx} 	
	\end{align*}
\end{enumerate}
	Substituting these constitutive relations into (\ref{generalphyslaws}), we obtain: 
\begin{align*}
	 & \idx{x_0}{x_0 + x} cu_t \rho dx = \idx{x_0}{x_0 + x}  r(x,t) \rho dx - \idx{x_0}{x_0 + x}  - \kappa u_{xx} dx \\
	\iff & \idx{x_0}{x_0 + x}  ( c \rho u_t - \kappa u_{xx} ) dx = \idx{x_0}{x_0 + x}  \rho r(x,t) dx \\
	\iff & \idx{x_0}{x_0 + x}  \left[ u_t - \frac{\kappa}{c \rho} u_{xx} \right] dx = \idx{x_0}{x_0 + x}  \frac{1}{c} r(x,t) dx 
\end{align*}
Since $]x_0, x_0 + \Delta x[$ is an arbitrary interval, equality of the integrals $\Rightarrow$ equality of the functions holds pointwise: 
\begin{align*}
	u_t - \frac{\kappa}{c \rho} u_{xx} = \frac{1}{c} r(x,t) 
\end{align*}
where $k := \kappa / cp$ is called the \dfn{diffusion constant.} If there is no external heat source, then the diffusion equation in one-dimension is given by: 
\begin{empheq}[box={\mybluebox[5pt]}]{equation}
    u_t - ku_{xx} = 0 
\end{empheq}
and if there is a heat source, i.e., $r(x,t) \neq 0$, then: 
\begin{empheq}[box={\mybluebox[5pt]}]{equation}
    u_t - ku_{xx} = \tilde{r}(x,t) 
\end{empheq}
$k$ encodes the thermal response time of the material. Now, we want to study the temperature in the rod by starting with an initial temperature distribution $u(x,0) := g(x)$. Boundary conditions would be of the form: 
\begin{itemize}[noitemsep]
	\item \dfn{Dirichlet Boundary Conditions}: $u(0,t) = h_1(t)$ and $u(L,t) = h_2(t)$. 
	\item \dfn{Neumann Boundary Conditions}: prescribe a heat flux at the ends: 
	\begin{align*}
		& u_x(0,t) = h_1(t) \\
		& u_x(L,t) = h_2(t) 
	\end{align*}
	\item \dfn{Robin Boundary Conditions}: heat flux on the ends is proportional to the difference between the temperature and its surroundings. In this case, we have an equation of the form: 
	\begin{align*}
		k u_x = \gamma (U-u) 
	\end{align*}
	where $\gamma > 0$ and $U$ is the temperature of the surroundings. 
	\begin{align*}
		& \Rightarrow u_x + \frac{\gamma }{k} u = \frac{\gamma'}{k} U \\
		& \Rightarrow u_x(0,t) + \alpha u(0,t) = h_1(t) \\
		& \Rightarrow u_x(L,t) + \alpha u(L, t) = h_2(t) 
	\end{align*}
	i.e., we have a linear combination of dirichlet and Neumann boundary conditions. 
\end{itemize}
If $h_1 = h_2 = 0$ then we have \dfn{homogeneous boundary conditions}. 

\subsubsection{Boundary Value Problems in $L_T:= ]0, L[ \times ]0, T]$}
Let $\partial p L_T :=$ the parabolic boundary of $L_T$. It is the union of the initial data (blue) and the boundary data (yellow) of the figure below. 
\begin{figure}[H]
	\centering 
	\label{parabolicbdry}
	\includegraphics[width=10cm]{pbdry}
\end{figure}
We require that $u \in C^{(2,1)}(L_T) \cap (\partial p L_T)$ (we have $C^{(2,1)}$ for two spatial dimensions and one time-dimension. The two main types of questions in this chapter are: 
\begin{align*}
& \text{ Boundary Value Problem:  } 
\begin{cases}
	 u_t - ku_{xx}  = r(x,t) & \text{ in } L_T \\
	 u(x,0) = g(x) & \text{ in } [0,L] \\
	 + \text{ B.C. } \\
\end{cases}	
\\
& \text{ Global Cauchy Problem: } \begin{cases}
	 u_t - ku_{xx}  = r(x,t) & \text{ in } \R \times ]0, T] \\
	 u(x,0) = g(x) & \text{ in } \R \\
	 + \text{ conditions on $u$ as } x \rightarrow \pm \infty  \\
\end{cases}
\end{align*}

\subsection{Derivation in $n \geq 1$}
The law of conservation of energy can be formulated as
\begin{center}
	Rate of Change of Heat Energy in a volume $V$ = Net Heat Flow Through $\partial V$
\end{center}
Again, define
\begin{align*}
	& e(x,t) := \text{ thermal energy / unit mass} \\
	& q(x,t) := \text{ heat flux (vector) } \\
	& \rho := \text{ mass density / unit volume} 
\end{align*}
Using the same constitutive relations as before and applying the divergence theorem, we obtain:
\begin{align*}
	\idx{V}{} \frac{\partial e}{\partial t} e(x,t) \rho dx & = \idx{V}{} r(x,t) \rho dx - \idx{\partial V}{} q(x,t) \cdot v d \sigma \\
	& = \idx{V}{} r(x,t) \rho dx - \idx{V}{} \text{div}(q(x,t)) dx 
\end{align*}
By the same constitutive relations, 
\begin{align*}
	& e(x,t) = cu(x,t) \\
	& q(x,t) = - \kappa \nabla u \\
	& \text{div}(\nabla u) = \Delta u
\end{align*}
Which gives us that
\begin{align*}
	\idx{V}{} c u_t \rho dx = \idx{V}{} r(x,t) \rho dx + \idx{V}{} \kappa \Delta u dx 
\end{align*}
Pointwise equality follows from the fact that $V \subseteq \R^n$ is arbitrary, and so
\begin{align*}
	& c u_t \rho = r(x,t)\rho + k \Delta u \\
	\iff & u_t - k \Delta u = \tilde{r}(x,t) \text{ in } \R^n \times ]0, \infty [
\end{align*}
\subsection{A solution by Separation of Variables}
\subsection{Uniqueness and Max Principles}
\subsubsection{Integral and Energy Method}
\subsubsection{Maximum Principles}
\subsection{The Fundamental Solution}
\subsubsection{Invariant Transformations}
\subsubsection{The Fundamental Solution $(n=1)$}
\subsection{Global Cauchy Problem}
\subsubsection{Homogeneous Case, $n=1$}
\subsubsection{Global Cauchy Problem and Uniqueness}
\subsection{Symmetric Random Walks $(n=1)$}
\subsection{Random Walks with Drift}
\subsection{Non-Homogeneous Case: Duhamel's Method}

\section{Laplace's Equation}
\section{Scalar Conservation Laws and First-Order Equations}
\section{Waves and Vibrations}
\subsection{Transversal Waves in a String}
\subsubsection{The Model}
\subsection{Separation of Variables}
Consider the Cauchy-Dirichlet Problem: 
\begin{align*}
\begin{cases}
	u_{tt} - c^2 u_{xx} = 0 & x \in ]0, L[, t > 0 \\
	u(x,0) = f(x), u_t(x,0) = g(x) \\
	+ \text{ boundary conditions} 
\end{cases}
\end{align*}
Assume that the boundary conditions are homogeneous, and we make the following Ansatz: there exist non-trivial solutions of the form:
\begin{align*}
	U(x,t) = X(x) T(t) 
\end{align*}
Inserting $U(x,t)$ into the PDE gives:
\begin{align*}
	X(x)T''(t) - c^2 T(t) X''(x) = 0 
\end{align*}
After some simplifications, we obtain: 
\begin{align*}
	\frac{1 T''(t)}{c^2 T(t)} = \frac{X''(x)}{X(x)} = \lambda
\end{align*}
where $\lambda$ is our separation constant. This gives us the following system of ODEs:
\begin{align*}
	T''(t) - \lambda^2 c^2 T(t) = 0 \\
	X''(x) - \lambda X(x) = 0 
\end{align*}
There are three cases: 
\begin{enumerate}[noitemsep]
	\item $\lambda = 0$: Then, $X''(x) = 0 \iff X = A + Bx$. Since the Boundary conditions are homogeneous, one has that $X(0) = A = 0 \iff A =0$ and similarly $B = 0$. Thus, we get that $X=0$, which is a trivial solution.
	\item $\lambda = \mu^2 > 0$: Then, $X''(x) + \mu^2X(x) = 0$ is a constant-coefficient second-order differential equation. Using techniques from ODEs, we will get that the solution is: 
	\begin{align}
		y = A e^{- \mu x} + B e^{\mu x} 
	\end{align}
	By the homogeneous boundary conditions, 
	\begin{align*}
		X(0) & = Ae + Be + e(A+B) = 0 \iff A = -B \\
		X(L) & = Ae^{-\mu L} + Be^{\mu L} = Ae^{-\mu L} - Ae^{\mu L} = A(e^{-\mu L} - e^{\mu L}) \iff A = 0 \iff B=0
	\end{align*}
	And once again we obtain a trivial solution. 
	\item $\lambda = \mu^2 < 0$. Then, by Euler's formula, 
	\begin{align}
		X(x) = A \sin (\mu x) + B \cos (\mu x) 	
	\end{align}
	From the initial data, we have:
	\begin{align*}
		X(0) & = A \sin (0) + B \cos(0) = 0 \iff B = 0 \\
		X(L) & = A \sin (\mu L) + B \cos (\mu L) = 0 \iff A \sin (\mu L) = 0 \iff \mu L = m \pi, m \in \mathbb{Z}
	\end{align*}
	and where $A$ is arbitrary. 
\end{enumerate}
Thus, the only non-trivial solutions are of the form: 
\begin{align*}
	X_m(x) = A \sin (\mu_m x),\ \mu_m = \frac{m \pi}{L} = \sqrt{\lambda}
\end{align*}
Inserting our value for $\lambda$ into the time ODE, we obtain: 
\begin{align*}
	T''(t) - \frac{c^2 m^2 \pi^2}{L^2} T(t) = 0 
\end{align*}
Solving this ODE gives: 
\begin{align}
	T_m(t) = C \cos (\mu_m ct) + D \sin (\mu_m ct) 	
\end{align}
for $C, D \in \R$. Using the Ansatz, assemble the solution:
\begin{align*} 
U_m (x,t)  & = X_m(x) T_m(t) \\
		   & = A \sin (\mu_m x) [ C \cos (\mu_m ct) + D \sin (\mu_m ct) ] \\
		   & = \sin (\mu_m x) [ a_m \cos (\mu_m ct) + b_m \sin (\mu_m ct) ], m \in \mathbb{N}
\end{align*} 
And as we did with the Heat Equation, to obtain the coefficients, match up to the initial data.

\subsection{Uniqueness and Energy Method}


\section{Fourier Series}
Idea: \textbf{Taylor Series}, recall that any smooth function can be approximated by a polynomial:
\begin{align*}
	f &: \R \rightarrow \R \\
	f(x) & \approx \sum_{n=0}^\infty \frac{f^{(n)} (x_0)(x-x_0)^n}{n!}
\end{align*}
\textbf{Fourier Series} are similar; they allow us to approximate any continuous function with a \emph{trigonometric polynomial}:
\begin{align}
	f(x) \approx \sum_{n=0}^n \left[ A_n \cos \left( \frac{n \pi x}{L} \right) + B_n \sin \left( \frac{n \pi x}{L} \right) \right] 	
\end{align}
A \dfn{trigonometric polynomial} is a collection of sines and cosines. 

\subsection{Definition of Fourier Series and Orthogonality}
\begin{definition}[Fourier Series of $f$]
	For a function $f(x)$, we define the \dfn{Fourier Series on $[-L, L]$} by: 
	\begin{align}
		FS[f(x)] := \frac{1}{2} A_0 + \sum_{n=1}^\infty A_n \cos \left (\frac{n \pi x}{L} \right) + \sum_{n=1}^\infty B_n \sin \left( \frac{n \pi x}{L} \right) 	
	\end{align}
	where
	\begin{align}
		A_n & := \frac{1}{L} \idx{-L}{L} f(x) \cos \left( \frac{n \pi x}{L} \right) dx \\
		B_n & := \frac{1}{L} \idx{-L}{L} f(x) \sin \left( \frac{n \pi x}{L} \right) dx 	
	\end{align}
\end{definition}
Before discussing orthogonality for functions, let's quickly recall how orthogonality works for vectors $v \in \R^n$. Recall that the standard basis $\{ \hat{\mathbf{e}}_1, ..., \hat{\mathbf{e}}_n \}$ is an orthonormal basis for $\mathbb{R}^n$. This means that, if we have a vector
\begin{align*}
	v = \begin{bmatrix}
		v_1 \\
		\vdots \\
		v_n
	\end{bmatrix}
\end{align*}
then, the dot product with the ith standard basis vector picks off the components: 
\begin{align*}
	v_i = \mathbf{v} \cdot \mathbf{\hat{e}}_i 
\end{align*}
The analog of a dot product for functions is the inner product. 
\begin{definition}[Inner Product]
	Given two functions $f$, $g$ on $[-L, L]$, we define the \dfn{inner product} to be: 
	\begin{align}
		\langle f, g \rangle := \idx{-L}{L} f(x) g(x) dx	
	\end{align}
	Which satisfies a number of properties (all of which follow from the linearity of integration):
	\begin{enumerate}[noitemsep]
		\item $\langle f, g+h \rangle = \idx{-L}{L} f(x) [ g(x) + h(x)] dx = \langle f, g \rangle + \langle f, h \rangle$
		\item $\langle f, g \rangle = \langle g, h \rangle $ for real-valued functions. 
		\item For $\lambda \in \R$, $\langle \lambda f, g \rangle = \lambda \rangle f, g \langle  = \langle f, \lambda g \rangle $
	\end{enumerate}
	This is called \dfn{bilinearity}. 
\end{definition}

\begin{definition}[$L^2$ Norm]
	The \dfn{$L^2$ norm} is defined as:
	\begin{align}
		||f|| := \left( \langle f, f \rangle \right)^{1/2} 	 = \left( \idx{-L}{L} f(x)^2 dx \right)^{1/2} 
	\end{align}
\end{definition}

\begin{definition}[Orthonormal Family of Functions]
	We say that a sequence of functions $\{ f_n \}_{n=1}^\infty$ form an \dfn{orthonormal family of functions} if: 
	\begin{align*}
		\langle f_m , f_n \rangle = \delta_{mn} 
	\end{align*}
\end{definition}

\begin{prop}
	The family of functions
	\begin{align}
	\left\{ \sin \left( \frac{n \pi x}{L} \right) \right\}_{n=1}^\infty 	
	\end{align}
	form an orthogonal family on $[-L, L]$.
\end{prop}

\begin{proof}
	If $m \neq n$, then by a series of tricks, we can show: 
	\begin{align}
		\idx{-L}{L}  \sin \left( \frac{n \pi x}{L} \right) \sin \left( \frac{m \pi x}{L} \right)dx 	= ... = 0 
	\end{align}
	Now we check its norm: 
	\begin{align*}
		\left\langle \sin \left( \frac{n \pi x}{L} \right) , \sin \left( \frac{m \pi x}{L} \right) \right\rangle & = \idx{-L}{L} \sin^2 \left( \frac{n \pi x}{L} \right) dx \\
		& = \idx{-L}{L} \frac{1}{2} - \frac{1}{2} \cos \left( \frac{n \pi x}{L} \right) dx \\
		& = \idx{-L}{L} \frac{1}{2} dx \\
		& = L 
	\end{align*}
	Not quite yet orthonormal, since $\left| \left| \sin \left( \frac{n \pi x}{L} \right)  \right| \right|_{L^2} = \sqrt{L}$. 
\end{proof}

\begin{remark}
	The exact same shows that the following forms an orthonormal family: 
	\begin{align*}
		\left\{ \cos \left( \frac{n \pi x}{L} \right) \right\}_{n=1}^\infty 
	\end{align*}
\end{remark}
Also, one has that $\left\langle \sin \left( \frac{n \pi x}{L} \right), \cos \left( \frac{n \pi x}{L} \right) \right\rangle =0$, which means that the following is an orthogonal family:
\begin{align}
	\left\{  \sin \left( \frac{n \pi x}{L} \right), \cos \left( \frac{n \pi x}{L} \right) \right\}_{n=0}^\infty  	
\end{align}
Also, 
\begin{align*}
 \ip{1}{\sin\left( \frac{n \pi x}{L} \right) } & = \idx{-L}{L} 1 \sin \left( \frac{n \pi x}{L} \right) dx = \left[ \frac{-L}{n \pi } \cos \left( \frac{n \pi x}{L} \right) \right]_{-L}^L  = 0 \\
 \ip{1}{\cos\left( \frac{n \pi x}{L} \right) } & = \idx{-L}{L} 1 \cos \left( \frac{n \pi x}{L} \right) dx = 0 \\
 \ip{1}{1} & = \idx{-L}{L} 1 dx = 2L 
\end{align*}
This tells us that
\begin{align}\label{orthogonal} 
	\left\{ 1, \sin \left( \frac{n \pi x}{L} \right), \cos \left( \frac{n \pi x}{L} \right) \right\}_{n=1}^\infty 
\end{align}
is orthogonal, and that 
\begin{align}
		\left\{ \frac{1}{\sqrt{2L}} , \frac{1}{\sqrt{L}} \sin \left( \frac{n \pi x}{L} \right),  \frac{1}{\sqrt{L}} \cos \left( \frac{n \pi x}{L} \right) \right\}_{n=1}^\infty 	
\end{align}
is orthonormal. \textbf{Question:} Is (\ref{orthogonal}) a basis of a function space? \textbf{Problem:} a function space is infinite-dimensional. We will show that if $\exists$ an $f(x) \in C^1$ that is orthogonal to (\ref{orthogonal}) $\forall n \in \mathbb{N}$, then $f(x) = 0$ . We will show this in multiple steps. The first will be the following theorem which allows us to obtain the Fourier Coefficients by taking inner products: 

\begin{theorem}
	Suppose that
	\begin{align}
		f(x) = \frac{1}{2} A_0 + \sum_{n=1}^N A_n \cos \left( \frac{n \pi x}{L} \right) + \sum_{n=1}^N B_n \sin \left( \frac{n \pi x}{L} \right) 	
	\end{align}
	Then, the coefficients are obtained by: 
	\begin{align*}
		A_n & = \frac{1}{L} \ip{f(x)}{\cos \left( \frac{n \pi x}{L} \right)} \\
		B_n & = \frac{1}{L} \ip{f(x)}{ \sin \left( \frac{n \pi x}{L} \right)}
	\end{align*}
\end{theorem}

\begin{remark} 
	We used this fact in separation of variables with the heat equation.
\end{remark}

\begin{proof}
	By orthogonality, for a fixed $m>0$, one has: 
	\begin{align*}
		\frac{1}{L} \ip{f(x)}{\cos \left( \frac{m \pi x}{L} \right)} & = \frac{1}{L} \ip{ \frac{1}{2} A_0}{ \cos \left( \frac{m \pi x}{L} \right)} + \sum_{n=1}^N \ip{A_n \cos \left( \frac{n \pi x}{L} \right)}{ \cos \left( \frac{m \pi x}{L} \right) } +  \\ & \sum_{n=1}^N \ip{B_n \sin \left(  \frac{n \pi x}{L} \right)}{ \cos \left( \frac{n \pi x}{L} \right)}  \\
		& = \frac{1}{L} A_m \ip{ \cos \left( \frac{m \pi x}{L} \right)}{ \cos \left( \frac{m \pi x}{L} \right)}  \\
		& = \frac{1}{L} A_m L \\
		& = A_m
	\end{align*}
	One has a similar argument for the $B_n$. If $m=0$, then: 
	\begin{align*}
		\frac{1}{L} \ip{f(x)}{1} = \frac{1}{L} \ip{\frac{1}{2} A_0}{1} = \frac{A_0}{2L} \idx{-L}{L} 1 dx = A_0
	\end{align*}
	So, in all cases, we agree with the Fourier Coefficients, which is what we wanted to show.
\end{proof}

\subsection{Convergence of Fourier Series}
\subsubsection{Modes of Convergence for Functions}
Consider $\{f_k \}_{k \in \mathbb{N}}$ and $f$ functions, $f: U \rightarrow \R$. In what ways can our sequence of functions converge to $f$? There are three that we will study in this section:

\begin{definition}[Pointwise Convergence]
	$f_k \rightarrow f$ \dfn{pointwise} if $\forall \varepsilon > 0$, $\forall x \in U$, $\exists \widetilde{k} \in \mathbb{N}$ such that $\forall k \geq \widetilde{k}$, 
	\begin{align}
		|f_k(x) - f(x)| < \varepsilon
	\end{align}
	Thus, for a fixed $x$, we have the convergence of the sequence of \emph{numbers}: 
	\begin{align}
		\lim_{k \rightarrow \infty} f_k(x) = f(x) 	
	\end{align}
\end{definition}

\begin{definition}[Uniformly Converge]
	$f_k \rightarrow f$ \dfn{uniformly} if $\forall \varepsilon > 0$, $\exists \widetilde{k}$ such that $\forall k \geq \widetilde{k}$, 
	\begin{align}
		\sup_{x \in U}|f_k(x) - f(x)| < \varepsilon	
	\end{align}
	(Essentially, this requires that the \emph{graphs} of $f_k$ become uniformly closer to that of $f$).
\end{definition}

\begin{definition}[$L^2$ Convergence / Mean-Square Convergence]
	$f_k \rightarrow f$ in $L^2(U)$ if $\forall \varepsilon > 0$, $\exists \widetilde{k} \in \mathbb{N}$ such that $\forall k \geq \widetilde{k}$, 
	\begin{align}
		\idx{U}{} |f_k(x) - f(x)|^2 dx < \varepsilon	
	\end{align}
\end{definition}

\begin{remark}
	These notions are not all equivalent. 
\end{remark}

\begin{ex}
	Define a sequence of functions as: 
	\begin{align}
		f_k(x) := \begin{cases}
			1 - kx & x \in \left[ 0, \frac{1}{k} \right[ \\
			0 & x \in \left] \frac{1}{k}, 1 \right] 
		\end{cases}	
	\end{align}
\end{ex}

\begin{claim}
	\begin{align}
		f(x) = \begin{cases}
			1 & x =0 \\
			0 & x \neq 0 
		\end{cases}	
	\end{align}
\end{claim}
\begin{claim}
	$f_k \rightarrow f$ pointwise.
\end{claim}

\begin{proof}
	If $x \neq 0$, $\exists k \in \mathbb{N}$ such that $\frac{1}{k} < x$, which proves that $f_k(x) = 0$. 
\end{proof}

\begin{claim}
	$f_k \rightarrow f$ in $L^2([0,1])$.
\end{claim}
\begin{proof}
	$L^2$ convergence is all about the area between the graphs:
	\begin{align*}
		\idx{0}{1} |f_k - f|^2 dx & = \idx{0}{1/k} (1-kx-0)^2 dx \\
		& = \left[ \frac{1-kx^3}{-k} \right]_0^{1/k}  \\
		& = \frac{1}{k} < \infty 
	\end{align*}
	Which proves that $f_k \rightarrow f$ in $L^2([0,1])$.
\end{proof}

\begin{claim}
	$f_k(x)$ does \emph{not} converge to $f$ uniformly. 
\end{claim}

\begin{proof}
	We observe that for a fixed $k$, and since we're suping over $[0,1]$, we can choose a $c$ in here. Let $x := \frac{1}{k^2}$. Then: 
	\begin{align*}
		\sup_{x \in [0,1]} |f_k(x) - f(x)| \geq \left| 1 - k \left(  \frac{1}{k^2} \right) - 0  \right| = \left| 1 - \frac{1}{k} \right| 
	\end{align*}
	Hence, it's impossible for 
	\begin{align*}
		\sup_{x \in [0,1] }|f_k(x) - f(x)| \rightarrow 0
	\end{align*}
	as $k \rightarrow \infty$.
\end{proof}
Bringing it back to functions, for an infinite series of functions, 
\begin{align*}
	f(x) = \sum_{n=1}^\infty f_n(x) = \lim_{N \rightarrow \infty} \sum_{n=1}^N f_n(x) 
\end{align*}
Define the partial sum $S_N$: 
\begin{align*}
	S_n (x) := \sum_{n =1}^N f_n(x) 
\end{align*}

\begin{definition}[Convergence of Series]
	The series
	\begin{align*}
		\sum_{n=1}^\infty f_n(x) \hspace{0.2cm} \text{ converges to $f(x)$...} 
	\end{align*}
	\begin{enumerate}[noitemsep]
		\item \dfn{Pointwise} if $S_N(x) \rightarrow f(x) $ pointwise. 
		\item \dfn{Uniformly} if $S_N(x) \rightarrow f(x)$ uniformly. 
		\item \dfn{$L^2$} if $S_N(x) \rightarrow f(x)$ in $L^2$.
	\end{enumerate}
\end{definition}

\begin{definition}[$L^2(U)$]
	The function space $L^2(U)$ is defined as: 
	\begin{align}
		L^2(U) := \left\{ f: U \rightarrow \R \text{ s.t. } \idx{U}{} |f(x)|^2 dx < \infty \right\} 	
	\end{align}
	\begin{itemize}[noitemsep]
		\item This is a function space with a lot of structure. 
		\item It gives us an equivalence class of functions which are equal up to a negligible set (one of ``measure'' zero). For example:
		\begin{align*}
			f(x) \equiv 0 \hspace{0.5cm} \text{ and } \hspace{0.5cm} \widetilde{f(x)} := \begin{cases}
				1 & x = 0 \\
				0 & x \neq 0 
			\end{cases}
		\end{align*}
		are identified as being the same in $L^2$.
	\end{itemize}
\end{definition}

\subsubsection{Bessel's Inequality and the Riemann-Lebesgue Lemma}

\begin{theorem}[Bessel's Inequality]
	Let $f \in L^2([-L, L])$. Then, 
	\begin{align}
		\frac{1}{2} A_0^2 + \sum_{n=1}^\infty (A_n^2 + B_n^2) \leq \frac{1}{L} \idx{-L}{L} [f(x)]^2 dx < \infty 	
	\end{align}
\end{theorem}

\begin{corollary}[Riemann-Lebesgue Lemma]
	If $f \in L^2([-L,L])$, then
	\begin{align}
		& \lim_{n \rightarrow \infty} \left( \frac{1}{L} \idx{-L}{L} f(x) \cos \left( \frac{n \pi x}{L} \right) dx \right) = \lim_{n \rightarrow \infty} A_n = 0  \\
		& \lim_{n \rightarrow \infty} \left( \frac{1}{L} \idx{-L}{L} f(x) \sin \left( \frac{n \pi x}{L} \right) dx \right) = \lim_{n \rightarrow \infty} B_n = 0 	
	\end{align}
\end{corollary}

\begin{proof}[Proof (Bessel's Inequality)]
	To do...
\end{proof}

\begin{theorem}[Pointwise Convergence of Fourier Series]
	Let $f \in C^1(]-L, L[)$. Then, 
	\begin{align*}
		f(x) = FS[f(x)] \text{ pointwise in } ]-L, L[
	\end{align*}
\end{theorem}

\begin{proof}
	To do...
\end{proof}

\begin{theorem}[Uniform Convergence]
	Let $f(x) \in C^2(]-L, L[)$. Then, 
	\begin{align*}
		FS[f(x)] = f(x) \text{ uniformly }
	\end{align*}
\end{theorem}

\begin{proof}
	$f \in C^2 \rightarrow f \in C^1$, which means we can apply the pointwise convergence: $\forall x \in ]-L, L[$, 
	\begin{align}
		\lim_{n \rightarrow \infty} S_N(x) = f(x) 	
	\end{align}
	Thus, 
	\begin{align*}
		|f(x) - S_N(x) | & = \left| \sum_{n=n+1}^\infty \left( A_n \cos \left( \frac{n \pi x}{L} \right) + B_n \sin \left( \frac{n \pi x}{L} \right) \right)  \right|  \\
		& \leq \sum_{n=n+1}^\infty |A_n| + \sum_{n=1}^\infty |B_n|
	\end{align*}
	\textbf{Fact}: we obtain, by integrating by parts, that if $f \in C^2$, then: 
	\begin{align*}
		|A_n| & \leq \frac{2L^2 M}{\pi^2} \frac{1}{n^2} \\
		|B_n| & \leq \frac{2L^2 M}{\pi^2} \frac{1}{n^2}
	\end{align*}
	where $M:= \max_{x \in [-L,L]} |f''(x)|$.
	\begin{remark}
		In general, if $f \in C^k$, then $|A_n|$, $|B_n| \leq C \frac{1}{n^k}$ (i.e., the smoother $f$ is the better chance of the series converging there is). using these bounds, we obtain: 
		\begin{align*}
			|f(x) - S_N(x)| \leq \frac{4L^2 M}{\pi^2} \sum_{n = n+1}^\infty \frac{1}{n^2}
		\end{align*}
		Since $\sum_{n=1}^\infty \frac{1}{n^2}$ converges, the tail must go to zero. Since none of the above depends on $x$, this means that
		\begin{align*}
			\sup_{x \in [-L, L]} |f(x) - f_N(x)| \rightarrow 0 
		\end{align*}
		as $N \rightarrow \infty$.
	\end{remark}
\end{proof}

\begin{remark}
	if $f (x) \in [-L,L]$, we get a Fourier Series which is defined on all of $\R$, i.e.: 
	\begin{center}
		$FS[f(x)]$ $\leftrightarrow$ $\tilde{f}(x)$ is a $2L$ periodic extension.
	\end{center}	
\end{remark}

\subsection{Sine and Cosine Series and Applications}
Fourier Series ``approximates'' $f(x)$ defined on $[-L, L]$. What about $f(x)$ defined on $[0,L]$, like we saw for data with, say, the heat equation?

\begin{ex}
	Solve 
	\begin{align*}
		\begin{cases}
			u_t - Du_{xx} = 0 & x \in [0,L], t > 0  \\
			u(0,t) = 0 \text{ } u(L,t) = 0 \\
			u(x,0) = f(x) 
		\end{cases}
	\end{align*}
	To solve this, we will first extend by even/odd extension so $[-L, L]$. We'll extend based on the boundary conditions:
	\begin{enumerate}[noitemsep]
		\item Dirichlet boundary conditions $\Rightarrow$ odd extensions. 
		\item Neumann boundary conditions $\Rightarrow$ even extensions.
	\end{enumerate}
	\textbf{Observe:} $f(x)$ is \emph{even}, and so $FS[f(x)]$ will be: 
	\begin{align*}
		A_n = \frac{1}{L} \idx{-L}{L} f(x) \cos \left( \frac{n \pi x}{L} \right) dx = \frac{2}{L} \idx{0}{L} f(x) \cos \left( \frac{n \pi x}{L} \right) dx 
	\end{align*}
	since the product of two even functions is again even, and
	\begin{align*}
		B_n = \frac{1}{L} \idx{-L}{L} f(x) \sin \left( \frac{n \pi x}{L} \right) dx = 0 
	\end{align*}
	since the product of an even and an odd function is odd, and we are integrating an odd function on a symmetric interval. So, $FS[f(x)]$ is just cosines. Similarly, if $f(x)$ is \emph{odd}, then $FS[f(x)]$ is just sines; all the cosine terms will integrate to zero.
\end{ex}

\begin{definition}[Fourier Cosine and Sine Series]
	Let $f(x)$ be defined on $[0,L]$. Then, the \dfn{Fourier Cosine} \dfn{Series} is:
	\begin{align}
	FCS[f(x)] := FS[f_{\text{even}} (x)] = \frac{1}{2} A_0 + \sum_{n=1}^\infty A_n \cos \left( \frac{n \pi x}{L} \right) 	
	\end{align}
	where
	\begin{align}
		A_n = \frac{2}{L} \idx{0}{L} f(x) \cos \left( \frac{n \pi x}{L} \right) dx 	
	\end{align}
	The \dfn{Fourier Sine Series} is: 
	\begin{align*}
		FSS[f(x)] := FS [ f_{\text{odd}} (x)] = \sum_{n=1}^\infty B_n \sin \left( \frac{n \pi x}{L} \right) 
	\end{align*}
	where
	\begin{align}
		B_n = \frac{2}{L} \idx{0}{L} f(x) \sin \left( \frac{n \pi x}{L} \right) dx 	
	\end{align}
\end{definition}
We are now ready to solve PDEs with Fourier Series. 

\subsubsection{Formal Solutions and Approximate Solutions}
Recall: we want to solve:
\begin{align}
		\begin{cases}
			u_t - Du_{xx} = 0 & x \in [0,L], t > 0  \\
			u(0,t) = 0 \text{ } u(L,t) = 0 \\
			u(x,0) = f(x) 
		\end{cases}	
\end{align}
If $f(x)$ is not a trig polynomial, then we'll try to approximate $f(x)$ by $FS[f(x)]$. We'll thus solve, 
\begin{align*}
	\begin{cases}
		v_t - Dv_{xx} = 0 \\
		\text{ $v$ satisfies some boundary condition} \\
		v(x,0) = FS[f(x)] 
	\end{cases}
\end{align*}
You then carry out separation of variables to find that $v(x,t)$ has a formal solutions (do not care about convergence, yet), and putting everything together as we did at the start of the semester gives us:
\begin{align*}
	v(x,t) = \sum_{n=1}^\infty \Box 
\end{align*}
Then, we can check to see if the formal solution converges, by considering the truncated solution $v_N(x,t)$, which is defined as:
\begin{align*}
	v_N(x,t) = \sum_{n=1}^N \Box
\end{align*}
Finally, we'll use the max principle to close the gap.
\begin{ex}
	Solve: 
	\begin{align*}
		\begin{cases}
			u_t - D u_{xx} = 0 & x \in [0, \pi], t \geq 0 \\
			u_x(0,t) = 0 & u_x(\pi,t) = 0 \\
			u(x,0) = \sin (x) 
		\end{cases}
	\end{align*}
\end{ex}
\textbf{Observe:} there is no $C^2$ solution to this PDE: 
\begin{align*}
	u_x(x,0) = \cos(x) \Rightarrow u_x(0,0) = 1 \neq 0 
\end{align*}
\begin{claim}
	We'll find a $C^\infty$ approximate solution that is within the threshold of $0.03$.
\end{claim}
First, since this problem has Neumann boundary conditions, we will extend the initial data by an even extension:
\begin{align*}
	v(x,0) := \begin{cases}
		\sin (x) & x \in [0, \pi] \\
		- \sin (x) & x \in [-\pi, 0] 
	\end{cases}
\end{align*}
And we compute the Fourier Cosine Series of the extended initial data:
\begin{align*}
	A_n & = \frac{2}{\pi} \idx{0}{\pi} \sin (x) \cos(nx) dx \\
	& = \frac{2}{\pi} \left( \left[ - \cos(nx) \cos(x) \right]_{0}^\pi - n \idx{0}{\pi} \sin(nx)\cos(x) dx    \right)  \\
	& = \frac{2}{\pi} \left( [-1(-1)^n (+1) +1] - n \idx{0}{\pi} \sin(nx) \cos(x) dx \right) \\
	& = \frac{2}{\pi} \left( (-1)^n + 1 - n \left( [\sin(x)\sin(nx)]_{0}^\pi - \idx{0}{\pi} n \cos(nx) \sin(x) dx \right)  \right) \\
	\frac{2}{\pi} \idx{0}{\pi} \sin(x) \cos(nx) dx & = \frac{2}{\pi} \left[ (-1)^n +1 + n^2 \idx{0}{\pi} \cos(nx) \sin(x) dx \right]  \\
	\frac{2}{\pi} (1-n^2) \idx{0}{\pi} \sin(x) \cos(nx) dx & = \frac{2}{\pi} ( (-1)^n+1) 
\end{align*}
and so
\begin{align*}
	A_n = \frac{2}{\pi} \idx{0}{\pi} \sin(x) \cos(nx) dx = \frac{2}{\pi} \frac{((-1)^n +1)}{1-n^2}
\end{align*}
For $n$ odd, $A_n =0$. Thus, $FCS \sin(x)$ is:
\begin{align*}
	FCS[\sin(x)] = \sum_{n=2, n \text{even}}^\infty \frac{2}{\pi} \frac{(-1)^n +1}{1-n^2} \cos \left( \frac{n \pi x}{L} \right) + \frac{2}{\pi} \\
	A_0 = \frac{2}{\pi} \idx{0}{\pi} \sin(x) dx = \left[ \frac{2}{\pi} (-\cos(x)) \right]_{0}^\pi = \frac{4}{\pi}
\end{align*}
and so
\begin{align*}
	FCS[\sin(x)] & = \frac{2}{\pi} + \sum_{n=1}^\infty \frac{4}{\pi} \frac{1}{1-(2n)^2} \cos \left( \frac{2n \pi x}{\pi} \right)  \\
	& = \frac{2}{\pi} - \sum_{n=1}^\infty \frac{4}{\pi} \frac{1}{4n^2 -1} \cos \left( 2n x \right) 
\end{align*}
Now, we want to solve:
	\begin{align*}
		\begin{cases}
			v_t - D v_{xx} = 0 & x \in [0, \pi], t \geq 0 \\
			v_x(0,t) = 0 & v_x(\pi,t) = 0 \\
			v(x,0) = \frac{2}{\pi} - \sum_{n=1}^\infty \frac{4}{\pi} \frac{1}{4n^2 -1} \cos \left( 2n x \right)
		\end{cases}
	\end{align*}
	Recall that by Separation of Variables, 
	\begin{align*}
		v(x,t) = \sum_{n=0}^\infty A_n e^{-n^2 Dt} \cos (nx)
	\end{align*}
	and so the formal solution is
	\begin{align*}
		v(x,t) = \frac{2}{\pi} - \frac{4}{\pi} \sum_{n=1}^\infty e^{-4n^2 Dt} \frac{\cos(2nx)}{4n^2-1}
	\end{align*}
	Let 
	\begin{align*}
		v_N(x,t) := \frac{2}{\pi} - \frac{4}{\pi} \sum_{n=1}^N e^{-4n^2 Dt} \frac{\cos(2nx)}{4n^2-1}
	\end{align*}
	Recall that by the Max principle:
	\begin{align}\label{maxprin}
	\max_{x \in [0,\pi]} |u(x,t) - v_N(x,t)| \leq \max_{x \in [0,\pi]} |u(x,0) - v_N(x,0)|	
	\end{align}
	But, observe that the right-hand-side of (\ref{maxprin}) is the uniform convergence of Fourier Series. That is, 
	\begin{align*}
		| \sin(x) - v_N(x,0)| & = \left| \sum_{n=N+1}^\infty \frac{4}{\pi} \frac{1}{4n^2 +1} \cos (2 \pi n x)  \right| \\
		& \leq \frac{4}{\pi} \sum_{n=N+1}^\infty \frac{1}{|4n^2-1|} \text{ (uniform convergence)} \\
		& \leq \frac{4}{\pi} \idx{N}{\infty} \left( \frac{1}{4x^2-1} \right) dx \text{ (integral test, always safer to take it at $N$)} \\
		& \leq \frac{4}{\pi} \idx{N}{\infty} \frac{1}{3x^2} dx \\
		& = \left[ \frac{4}{\pi} \frac{1}{3} \left( \frac{-1}{x} \right) \right]_{N}^\infty \\
		& = \frac{4}{3\pi} \frac{1}{N}
	\end{align*}
	This implies that
	\begin{align*}
		\max_{x \in [0,\pi]} | \sin(x) - v_N(x,0)| \leq \frac{4}{3\pi} \frac{1}{N}
	\end{align*}
	So, if I want the solution to be within $0.03$ of the true solution, by the max principle: 
	\begin{align*}
		|u(x,t) - v_N(x,t)| \leq |u(x,0) - v_N(x,0)| \leq \frac{4}{3 \pi} \frac{1}{N} \leq \frac{4}{3 \cdot 3} \frac{1}{N} = \frac{4}{9} \frac{1}{N} \approx \frac{3}{100} \iff N \approx \frac{400}{27} = \frac{400}{25} = 16
	\end{align*}
	and thus, the solution is:
	\begin{align}
	u(x,t) = \frac{2}{\pi} - \frac{4}{\pi} \sum_{n=1}^{17} e^{-4n^2Dt} \frac{\cos(2n x)}{4n^2 -1} \pm 0.03	
	\end{align}
	
	
	\begin{ex}
		We can also do it for the wave equation. Solve:
		\begin{align*}
			\begin{cases}
				u_{tt}-u_{xx} = 0 & x \in [0,\pi], t > 0 \\
				u(0,1) = 0, u(\pi,1) = 0 \\
				u(x,0) = x^3(x-\pi)^3, u_t(x,0) = 0 
			\end{cases}
		\end{align*}
	\end{ex}
	The steps one would take:
	\begin{enumerate}[noitemsep]
		\item Compute the $FSS x^3(x-\pi)^3$. 
		\item The formal solution will be a big mess: $v(x,t) = \sum_{n=0}^\infty \Box$ 
		\item Max estimate, assuming that $f(x)$ extended is $C^2$, will give us the bounds
		\begin{align*}
			|u(x,t) - v_N(x,t)| \leq \max_{x \in [0,\pi]} |u(x,0) - v_N(x,0)| 
		\end{align*}
		and then you'd re-run the uniform convergence proof as we did for the heat equation example to get something quantitative.  
	\end{enumerate}
\end{document}